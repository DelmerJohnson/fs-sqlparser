{
module SqlLexer
open System
open SqlParser   
open Microsoft.FSharp.Text.Lexing
open Microsoft.FSharp.Text.Parsing
open System.Text

let keywords =   
    [   
        "SELECT", SELECT;   
        "FROM", FROM;   
        "WHERE", WHERE;   
        "ORDER", ORDER;   
        "BY", BY;   
        "JOIN", JOIN;   
        "INNER", INNER;   
        "LEFT", LEFT;   
        "RIGHT", RIGHT;   
        "ASC", ASC;   
        "DESC", DESC;   
        "AND", AND;   
        "OR", OR;   
        "ON", ON;   
        "AS", AS;
        "PERCENT", PERCENT;
        "TOP", TOP;
    ] |> Map.ofList   
 
let ops =   
    [   
        "=",    EQ;   
        "<",    LT;   
        "<=",   LE;   
        ">",    GT;   
        ">=",   GE;   
    ] |> Map.ofList   
}   
 
let char        = ['a'-'z' 'A'-'Z']   
let digit       = ['0'-'9']   
let int         = '-'?digit+   
let float       = '-'?digit+ '.' digit+   
let dot			= '.'
let identifier  = char(char|digit|['-' '_'])*   
let whitespace  = [' ' '\t']   
let newline     = "\n\r" | '\n' | '\r'  
let operator    = ">" | ">=" | "<" | "<=" | "="  
let lparen		= '('
let rparen		= ')'
let comma		= ','

rule tokenize = parse   
| whitespace    { tokenize lexbuf }   
| newline       { lexbuf.EndPos <- lexbuf.EndPos.NextLine; tokenize lexbuf; }   
| operator      { ops.[LexBuffer<_>.LexemeString lexbuf] }   
| int           { INT(LexBuffer<_>.LexemeString lexbuf) }   
| float         { FLOAT(LexBuffer<_>.LexemeString lexbuf) }
| identifier    { match keywords.TryFind((LexBuffer<_>.LexemeString lexbuf).ToUpper()) with   
                  | Some(token) -> token   
                  | None -> ID(LexBuffer<_>.LexemeString lexbuf) }    
| dot			{ DOT } 
| comma			{ COMMA }
| lparen		{ LPAREN }
| rparen		{ RPAREN }
| eof           { EOF }


